<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta http-equiv="Content-Style-Type" content="text/css" />
<meta name="generator" content="pandoc" />

<meta name="author" content="Giovanni Fossati" />


<title>Machine-Learning-based Assessment of the quality of weight-lifting exercises</title>

<script src="report_files/jquery-1.11.0/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<link href="report_files/bootstrap-2.3.2/css/cerulean.min.css" rel="stylesheet" />
<link href="report_files/bootstrap-2.3.2/css/bootstrap-responsive.min.css" rel="stylesheet" />
<script src="report_files/bootstrap-2.3.2/js/bootstrap.min.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #f8f8f8; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
pre, code { background-color: #f8f8f8; }
code > span.kw { color: #204a87; font-weight: bold; }
code > span.dt { color: #204a87; }
code > span.dv { color: #0000cf; }
code > span.bn { color: #0000cf; }
code > span.fl { color: #0000cf; }
code > span.ch { color: #4e9a06; }
code > span.st { color: #4e9a06; }
code > span.co { color: #8f5902; font-style: italic; }
code > span.ot { color: #8f5902; }
code > span.al { color: #ef2929; }
code > span.fu { color: #000000; }
code > span.er { font-weight: bold; }
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<link rel="stylesheet" href="gf_small_touches.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
</style>
<div class="container-fluid main-container">


<div id="header">
<h1 class="title">Machine-Learning-based Assessment of the quality of weight-lifting exercises</h1>
<h4 class="author"><em>Giovanni Fossati</em></h4>
</div>


<div id="introduction" class="section level2">
<h2>INTRODUCTION</h2>
<p>The rapid diffusion of sensors able to record physical parameters associated with motion (<em>e.g.</em> accelerometers), in dedicated devices and more importantly in general consumer electronics available/used by a broader population has sparked a great interest in developing applications taking advantage of these motion-related data. One area of particular interest concerns fitness-related activities.</p>
<p>This report summarizes the results of the development, and testing, of a <em>Machine Learning</em> model able to recognize the <em>quality</em> of a simple weight lifting exercise, namely whether or not it was performed appropropriately (and hence safely and effectively).</p>
<p>We used the dataset put together by the <a href="http://groupware.les.inf.puc-rio.br/har">research group on Human Activity Recognition</a> at the PUC of Rio de Janeiro.</p>
<hr />
</div>
<div id="summary-of-results" class="section level2">
<h2>SUMMARY OF RESULTS</h2>
<p>We tested three types of ML algorithms, all <em>tree-based</em> methods: <em>CART</em> trees, <em>boosted</em> trees, and <em>random forest</em>.</p>
<p>The first two methods failed to yield high quality results. This may have been caused by less than ideal choice of parameters, although in most cases we run them with the default values from <code>caret</code>, which are expected to be reasonable for decent results.</p>
<p><strong>Random forest</strong> models produced high quality results, with accuracies exceeding 99%, both in the built-in <em>Out Of the Bag</em> resampling, and on our separate <em>testing</em> subset.</p>
<p>Beside its clearly better performance, the choice of a random forest as an ensemble method is supported by its ability to handle multi-class problems.</p>
<p>We ran <em>random forest</em> models with <strong>three different <em>internal</em> cross-validation</strong> setups (implemented through the <code>trainControl()</code> function of <code>caret</code>): * 4-fold Cross-Validation, * bootstrap, and * <em>Leave Group Out Cross Validation</em>.</p>
<p>As noted, the trained models achieved exceptional accuracy in the ability of predicting the <em>outcome</em> variable <code>classe</code>, not only when tested against the 20-entries project benchmark, but more importantly when tested against the portion (25%) of the full dataset that we set aside for __validation_.</p>
<p>The results of a <em>random forest</em> model are not easily interpretable, even in presence of physically/motion based predictors. Nevertheless, as illustrated in some example plots, the data contain fairly clear pattern and differences between categories of exercise quality, that can be related to the slight differences in the motion of the body and weight dumbbell, and that are apparently very well picked out by the algorithm.</p>
<hr />
</div>
<div id="the-data-set" class="section level2">
<h2>THE DATA SET</h2>
<p>The data for the project were made available from the Coursera ML course webpage. Two separate sets were posted:</p>
<ul>
<li><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv">a <em>training</em> dataset</a>. This set comprises a little over 16,000 entries for 160 variables.</li>
<li><a href="https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv">a <em>testing</em> dataset</a>, to be used as a final project benchmark, comprising 20 “anonymized” entries.</li>
</ul>
<div id="structure" class="section level3">
<h3>Structure</h3>
<p>The dataset comprises 160 variables:</p>
<ul>
<li>152 actual <em>predictors</em>, <em>i.e.</em> the sensor data.</li>
<li>1 is the quality <em>class</em> of the exercise (<code>classe</code>, taking values <em>A</em>, <em>B</em>, <em>C</em>, <em>D</em>, <em>E</em>).</li>
<li>7 are auxiliary variables:
<ul>
<li>the <em>user</em> name (<code>user_name</code>).</li>
<li>3 time stamp related variables: <code>raw_timestamp_part_1</code>, <code>raw_timestamp_part_2</code>, <code>cvtd_timestamp</code>.</li>
<li>2 <em>exercise window</em> markers/counters: <code>new_window</code>, <code>num_window</code>.</li>
</ul></li>
</ul>
</div>
<div id="the-sensor-data" class="section level3">
<h3>The sensor data</h3>
<p>As described in the paper by Velloso et al. [REF], four <em>inertial measurement units</em> (IMU) where setup, placed<br />on <em>belt</em>, <em>arm</em>, <em>forearm</em>, <em>dumbbell</em>. Each sensor measured 3-axes acceleration, gyroscope and magnetometer data at high cadence (45 Hz). These data were processed to yield 13 timed variables for each sensor:</p>
<ul>
<li><em>total acceleration</em>.</li>
<li><em>roll</em>, <em>pitch</em>, <em>yaw</em> angles.</li>
<li><em>x</em>, <em>y</em>, <em>z</em> values for <em>gyroscope</em>, <em>acceleleration</em>, and <em>magnetometer</em>.</li>
</ul>
<p>For instance, for the <em>belt</em> sensor the <em>basic timed data</em> are: <code>total_accel_belt</code>, <code>roll_belt</code>, <code>pitch_belt</code>, <code>yaw_belt</code>, <code>gyros_belt_x</code>, <code>gyros_belt_y</code>, <code>gyros_belt_z</code>, <code>accel_belt_x</code>, <code>accel_belt_y</code>, <code>accel_belt_z</code>, <code>magnet_belt_x</code>, <code>magnet_belt_y</code>, <code>magnet_belt_z</code>.</p>
<p>The dataset therefore comprises <span class="math">\(4 \times 13 = 52\)</span> <em>basic timed data</em>.</p>
<p>In addition to these, several statistical summaries are computed and reported for each exercise <em>window</em>, for each sensor:</p>
<ul>
<li>For <code>total_accel</code>, its variance <code>var_accel</code>.</li>
<li>For each of the three angles: <code>avg</code>, <code>stddev</code>, <code>var</code>, <code>kurtosis</code>, <code>skewness</code>, <code>max</code>, <code>min</code>, <code>amplitude</code> (<span class="math">\(3 \times 8\)</span> variables).</li>
</ul>
<p>These <span class="math">\(1 + 24 = 25\)</span> statistical summaries for each sensor add another <span class="math">\(100\)</span> variables to the dataset for a total of <span class="math">\(152\)</span> variables.</p>
<p>It is worth emphasizing that the dataset presents <em>timed</em> and <em>summary</em> variables all together in one table. While this may be practically convenient, it makes this dataset <em>un-tidy</em> by combining variables of different nature. Fortunately the two types of variables can be easily separated on the basis of the value of the <code>new_window</code> auxiliary variable, which has value <code>no</code> for entries corresponding to timed data, and <code>yes</code> for their statistical summaries over each exercise window.</p>
<hr />
</div>
</div>
<div id="data-preparation" class="section level2">
<h2>DATA PREPARATION</h2>
<div id="loading" class="section level3">
<h3>Loading</h3>
<pre class="sourceCode r"><code class="sourceCode r">full &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./pml-training.csv&quot;</span>, <span class="dt">na.strings=</span><span class="kw">c</span>(<span class="st">&quot;#DIV/0!&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;NA&quot;</span>), <span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>)
full &lt;-<span class="st"> </span><span class="kw">add_new_variables</span>(full)
alt.full &lt;-<span class="st"> </span><span class="kw">tidy_df</span>(full)</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">TEST &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;./pml-testing.csv&quot;</span>, <span class="dt">na.strings=</span><span class="kw">c</span>(<span class="st">&quot;#DIV/0!&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;NA&quot;</span>), <span class="dt">stringsAsFactors=</span><span class="ot">FALSE</span>)
alt.TEST &lt;-<span class="st"> </span><span class="kw">tidy_df</span>(TEST)</code></pre>
</div>
<div id="cleaningtidying" class="section level3">
<h3>Cleaning/Tidying</h3>
<div id="non-sensor-variables" class="section level4">
<h4>Non-sensor variables</h4>
<p>Some variables should be discarded because associated with very specific aspects of the experiment that should be irrelevant from the point of view of its goal, such as <em>window</em> flags and <em>time stamps</em>.<br />These are the excluded variables: <code>X</code>, <code>user_name</code>, <code>new_window</code>, <code>num_window</code>, <code>cvtd_timestamp</code>, <code>raw_timestamp_part_1</code>, <code>raw_timestamp_part_2</code>.</p>
<p>Beside their intrinsic irrelevance, keeping these in would likely strongly drive the results in a completely spurious and meaningless way, because for instance the algorithm may hook on the <code>user_name</code> or <code>num_window</code>.</p>
</div>
<div id="individual-measurements-vs-summaries-the-new_window-variable" class="section level4">
<h4>Individual measurements <em>vs</em> <em>summaries</em> : the <code>new_window</code> variable</h4>
<p>To the best of my understanding, the dataset combines two different kinds of <em>observations</em>:</p>
<ul>
<li>single measurements of the main observables from the sensors, with some time cadence, and organized in <em>windows</em>, which are numbered (<code>num_window</code> variable).<br />These data have <code>new_window == &quot;no&quot;</code>.</li>
<li>statistical summaries of the measurements of each main observable over each <em>window</em>.<br />These data have <code>new_window == &quot;yes&quot;</code>, and</li>
</ul>
<p>We restricted our analysis to the 52 variables representing individual <em>timed</em> measurements, discarding the <em>summary</em> data.</p>
<pre class="sourceCode r"><code class="sourceCode r">alt.full &lt;-<span class="st"> </span><span class="kw">subset</span>(alt.full, new_window ==<span class="st"> &quot;no&quot;</span>)
alt.full.good &lt;-<span class="st"> </span><span class="kw">select_proper_vars</span>(alt.full)
alt.TEST.good &lt;-<span class="st"> </span><span class="kw">select_proper_vars</span>(alt.TEST)
alt.user &lt;-<span class="st"> </span>alt.full$user_name</code></pre>
<p>We also filtered out variables with <code>NA</code>, which basically means filtering against the <em>summary</em> variables.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># columns without ANY NA</span>
alt.tt &lt;-<span class="st"> </span><span class="kw">colSums</span>(<span class="kw">is.na</span>(alt.full.good)) ==<span class="st"> </span><span class="dv">0</span>

alt.full.select &lt;-<span class="st"> </span>alt.full.good[, alt.tt]
alt.TEST.select &lt;-<span class="st"> </span>alt.TEST.good[, alt.tt]</code></pre>
</div>
</div>
<div id="some-exploratory-plots" class="section level3">
<h3>Some exploratory plots</h3>
<div id="features-plotted-vs.sequence-index-and-color-coded-by-user_name-and-classe" class="section level4">
<h4>Features plotted vs. sequence index, and color coded by <code>user_name</code> and <code>classe</code></h4>
<p>These kind of plots shows that some of the features seem to correlated very strongly with the <em>user</em>, even more than with their <code>classe</code>, somewhat oddly.</p>
<p>This suggest that the training to predict the quality parameter of the weight lifting exercise (<code>classe</code>) that we can achieve with this dataset may not be easily generalized.</p>
<p><img src="figures/plots-examine2b.png" title="plot of chunk plots-examine2b" alt="plot of chunk plots-examine2b" width="600" style="display: block; margin: auto auto auto 0;" /></p>
<p><img src="figures/plots-examine2c.png" title="plot of chunk plots-examine2c" alt="plot of chunk plots-examine2c" width="600" style="display: block; margin: auto auto auto 0;" /></p>
</div>
<div id="feature-vs.feature-plots-with-separate-panels-by-classe" class="section level4">
<h4>Feature vs. Feature plots with separate panels by <code>classe</code></h4>
<p>This second set of example plots shows that there are indeed some reasonably recognizable patterns allowing to distinguish between different <code>classe</code> categories.</p>
<p>The expectation is that the ML algorithm will be able to identify them and build on them a classification scheme.</p>
<p><img src="figures/plots-more_1.png" title="plot of chunk plots-more_1" alt="plot of chunk plots-more_1" width="600" style="display: block; margin: auto auto auto 0;" /></p>
<p><img src="figures/plots-more_2.png" title="plot of chunk plots-more_2" alt="plot of chunk plots-more_2" width="600" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</div>
</div>
</div>
<div id="about-feature-selection" class="section level2">
<h2>ABOUT FEATURE SELECTION</h2>
<div id="zerolow-variance-predictors" class="section level3">
<h3>Zero/low variance predictors</h3>
<p>We checked the dataset for <em>un-informative</em> predictors, namely variables taking (nearly) unique values or having very little variance in their values.<br />The <code>caret</code> package provides a very convenient function to perform this quality-check, <code>nearZeroVar()</code>.</p>
<p>None of the 52 features meets the criteria for exclusion on the basis of <em>near Zero Variance</em>.<br />The full results of running it on our dataset (<code>nearZeroVar(alt.full.select, saveMetrics=TRUE)</code>) are reported in the <strong>Appendix</strong>.</p>
</div>
<div id="collinearity-between-predictors" class="section level3">
<h3><em>Collinearity</em> between predictors</h3>
<p>The presence of correlated predictor is undesirable because it can bias/mislead the modeling and in any case it may lead to run a model with an unnecessarily large(r) number of predictors. Although some ML algorithms are not negatively affected, it is generally safe to exclude correlated pr edictors.</p>
<p>For <em>tree-based</em> models it is actually recommended to clean the data set of correlated predictors because they end up sharing their overall <em>importance</em>, thus appearing to be less significant than they actually are.</p>
<p>We took advantage of the <code>caret</code> function <code>findCorrelation()</code> to identify variables whose absolute correlation value exceeds a set threshold (we chose 0.75) and obtain a list of variables to exclude selected among those with high correlation.</p>
<p>The actual predictors filtering was done applying this method just on the <em>training</em> subset (see below).</p>
<hr />
</div>
</div>
<div id="data-splitting-new-training-and-testing-subsets" class="section level2">
<h2>DATA SPLITTING: “NEW” <em>TRAINING</em> AND <em>TESTING</em> SUBSETS</h2>
<p>For validation purposes we split the full dataset in two subsets:</p>
<ul>
<li>a <em>training</em> subset, comprising 75% of the data.</li>
<li>a <em>testing</em> subset, comprising 25% of the data.</li>
</ul>
<p><strong>This <em>training</em> / <em>testing</em> split should not be confused with the original two datasets</strong>, which unfortunately are named also <em>training</em> and <em>testing</em>.</p>
<p>We are splitting the original <em>training</em> large dataset in two to be able to have an independent validation of the models, beyond what may already be done internally by some ML algorithms or by <code>caret</code> wrapped around them (<em>e.g.</em> by bootstrapping, or the built-in randomization and subsetting of <em>random forest</em> methods).</p>
<pre class="sourceCode r"><code class="sourceCode r">seed.split &lt;-<span class="st"> </span><span class="dv">12468</span>
<span class="kw">set.seed</span>(seed.split)
i.train.alt &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> alt.full.select$classe, <span class="dt">p=</span><span class="fl">0.75</span>, <span class="dt">list=</span><span class="ot">FALSE</span>)

alt.training &lt;-<span class="st"> </span>alt.full.select[i.train.alt, ]
alt.testing &lt;-<span class="st"> </span>alt.full.select[-i.train.alt, ]</code></pre>
<div id="feature-selection-on-training-testing-subsets" class="section level3">
<h3>Feature selection on <em>training</em> / <em>testing</em> subsets</h3>
<p>In the spirit of truly preserving the independence of the <em>testing</em> data subset, we performed the correlation-based feature reduction on the basis of the correlation between variables computed on the <em>training</em> subset instead of the full dataset, and applied the same variables filtering to the <em>testing</em> subset.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># correlation filtering done on the training subset</span>
alt.allCorr &lt;-<span class="st"> </span><span class="kw">cor</span>(alt.training[, -<span class="dv">1</span>])
i.fC<span class="fl">.75</span>.alt &lt;-<span class="st"> </span><span class="kw">findCorrelation</span>(alt.allCorr, <span class="dt">cutoff=</span><span class="fl">0.75</span>)</code></pre>
<p>The following plot shows the correlation matrix, with variables ordered on the basis of their <em>clustering</em>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">corrplot</span>(alt.allCorr, <span class="dt">order=</span><span class="st">&quot;hclust&quot;</span>, <span class="dt">method=</span><span class="st">&quot;color&quot;</span>, 
         <span class="dt">col=</span><span class="kw">color1</span>(<span class="dv">20</span>), <span class="dt">cl.length=</span><span class="dv">21</span>, <span class="dt">tl.cex=</span><span class="fl">0.8</span>, <span class="dt">tl.col=</span><span class="st">&quot;black&quot;</span>, <span class="dt">mar=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">1</span>,<span class="dv">0</span>))</code></pre>
<p><img src="figures/split_data-3.png" title="plot of chunk split_data-3" alt="plot of chunk split_data-3" width="800" style="display: block; margin: auto auto auto 0;" /></p>
<p>On the basis of their correlation, with a threshold of 0.75, these are the variables that would be excluded.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># variables to be excluded</span>
<span class="kw">colnames</span>(alt.training)[i.fC<span class="fl">.75</span>.alt<span class="dv">+1</span>]
##  [1] &quot;accel_belt_z&quot;      &quot;roll_belt&quot;         &quot;accel_belt_y&quot;      &quot;total_accel_belt&quot; 
##  [5] &quot;accel_dumbbell_z&quot;  &quot;accel_belt_x&quot;      &quot;pitch_belt&quot;        &quot;magnet_dumbbell_x&quot;
##  [9] &quot;accel_dumbbell_y&quot;  &quot;magnet_dumbbell_y&quot; &quot;accel_dumbbell_x&quot;  &quot;accel_arm_x&quot;      
## [13] &quot;accel_arm_z&quot;       &quot;magnet_arm_y&quot;      &quot;magnet_belt_y&quot;     &quot;accel_forearm_y&quot;  
## [17] &quot;gyros_arm_y&quot;       &quot;gyros_forearm_z&quot;   &quot;gyros_forearm_y&quot;   &quot;gyros_dumbbell_x&quot;

<span class="co"># variables selection</span>
alt.training.cut75 &lt;-<span class="st"> </span>alt.training[, -(i.fC<span class="fl">.75</span>.alt<span class="dv">+1</span>)]
alt.testing.cut75 &lt;-<span class="st"> </span>alt.testing[, -(i.fC<span class="fl">.75</span>.alt<span class="dv">+1</span>)]</code></pre>
<hr />
</div>
</div>
<div id="modeling" class="section level2">
<h2>MODELING</h2>
<p>We tested three types of ML algorithms, all within the framework provided by <code>caret</code>, and all generally speaking <em>tree-based</em> models.</p>
<ul>
<li>CART trees, namely <code>rpart2</code>.</li>
<li><em>boosted</em> tree, namely <code>gbm</code>.</li>
<li><em>random forest</em>, namely <code>rf</code>.</li>
</ul>
<p>The first two methods failed to yield high quality results, in fact in some cases their performance on the <em>testing</em> subset was very poor.<br />This may have been caused by less than ideal choice of parameters, but in most cases we let the modeling run with the default values from <code>caret</code>, which are expected to be reasonable for decent results.<br />We have to acknowledge that in some cases, in particular for the <code>gbm</code> models, the running time turned out to be very long and the memory requirements large enough to make it impractical, and we did not pursue those models more extensively.</p>
<p>On the other hand <strong>random forest</strong> models produced high quality results, with accuracies exceeding 99%, both in the built-in <em>Out Of the Bag</em> resampling, and on our separate <em>testing</em> subset.</p>
<p>In the next three sections we illustrate the results of <strong>random forest</strong> models run with <strong>three different <em>internal</em> cross-validation</strong> setups, implemented through the <code>trainControl()</code> function of <code>caret</code>:</p>
<ul>
<li><code>cv</code>: Cross-Validation, 4-fold (<em>i.e.</em> 75%/25% splits).</li>
<li><code>boot</code> (the default): bootstrap, 25 repeats.</li>
<li>’LGOCV`: Leave Group Out Cross Validation, 25 repeats, 75%/25% train/test splits of the data.</li>
</ul>
<p>In all cases we also tried a set of values for <code>mtry</code>, which regulates how many predictors are selected in the <em>random forest</em> random subsetting of variables.</p>
<div id="random-forest-case-1-4-fold-cv" class="section level3">
<h3><em>Random Forest</em> case 1 : 4-fold <em>CV</em></h3>
<p>With <code>mtry = 2, 6, 10, 18, 26, 34</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mtry.values &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">26</span>, <span class="dv">34</span>)

ctrl.rf1c &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number=</span><span class="dv">4</span>)

seed.rf1c &lt;-<span class="st"> </span><span class="dv">16790</span>; <span class="kw">set.seed</span>(seed.rf1c)
mod.alt.rf1c &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> alt.training.cut75[, -<span class="dv">1</span>], 
                      <span class="dt">y =</span> alt.training.cut75$classe, 
                      <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
                      <span class="dt">trControl =</span> ctrl.rf1c,
                      <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">mtry =</span> mtry.values),
                      <span class="dt">importance =</span> <span class="ot">TRUE</span>, 
                      <span class="dt">proximity =</span> <span class="ot">TRUE</span>)</code></pre>
<div id="fit-summary" class="section level4">
<h4>Fit Summary</h4>
<pre class="sourceCode r"><code class="sourceCode r">mod.alt.rf1c
## Random Forest 
## 
## 14414 samples
##    32 predictors
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Cross-Validated (4 fold) 
## 
## Summary of sample sizes: 10811, 10810, 10811, 10810 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD
##   2     1         1      0.004        0.005   
##   6     1         1      0.003        0.004   
##   10    1         1      0.003        0.004   
##   20    1         1      0.003        0.004   
##   30    1         1      0.003        0.004   
##   30    1         1      0.003        0.004   
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 6.
mod.alt.rf1c$finalModel
## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##         OOB estimate of  error rate: 0.61%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4100    2    0    1    1   0.0009747
## B   17 2762   10    0    0   0.0096809
## C    0   19 2484   10    1   0.0119332
## D    1    0   21 2337    2   0.0101652
## E    0    0    1    2 2643   0.0011338
mod.alt.rf1c$results
##   mtry Accuracy  Kappa AccuracySD  KappaSD
## 1    2   0.9898 0.9871   0.003952 0.005002
## 2    6   0.9912 0.9889   0.002983 0.003775
## 3   10   0.9901 0.9875   0.003060 0.003873
## 4   18   0.9880 0.9848   0.003000 0.003797
## 5   26   0.9830 0.9785   0.003199 0.004049
## 6   34   0.9778 0.9719   0.003414 0.004320</code></pre>
</div>
<div id="predictions-on-testing-subset" class="section level4">
<h4>Predictions on <em>testing</em> subset</h4>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1c.test75 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1c, alt.testing.cut75, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># confusion matrix</span>
<span class="kw">confusionMatrix</span>(alt.testing.cut75$classe, pred.rf1c.test75)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1364    3    0    0    0
##          B    0  919    7    0    3
##          C    0    6  824    8    0
##          D    0    0   12  772    2
##          E    0    0    0    1  881
## 
## Overall Statistics
##                                         
##                Accuracy : 0.991         
##                  95% CI : (0.988, 0.994)
##     No Information Rate : 0.284         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.989         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000    0.990    0.977    0.988    0.994
## Specificity             0.999    0.997    0.996    0.997    1.000
## Pos Pred Value          0.998    0.989    0.983    0.982    0.999
## Neg Pred Value          1.000    0.998    0.995    0.998    0.999
## Prevalence              0.284    0.193    0.176    0.163    0.185
## Detection Rate          0.284    0.191    0.172    0.161    0.183
## Detection Prevalence    0.285    0.193    0.175    0.164    0.184
## Balanced Accuracy       1.000    0.994    0.987    0.992    0.997</code></pre>
</div>
<div id="predictions-on-test-subset-the-20-benchmark-values-for-the-project" class="section level4">
<h4>Predictions on <em>TEST</em> subset (the 20 benchmark values for the Project)</h4>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1c.TEST &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1c, alt.TEST.select, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># comparison with &quot;truth&quot;</span>
pred.rf1c.TEST ==<span class="st"> </span>answers
##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [20] TRUE</code></pre>
</div>
<div id="variable-importance" class="section level4">
<h4>Variable Importance</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImp</span>(mod.alt.rf1c, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>)
## rf variable importance
## 
##   variables are sorted by maximum importance across the classes
##   only 20 most important variables shown (out of 32)
## 
##                         A    B    C    D    E
## yaw_belt             71.8 61.7 57.9 69.8 48.8
## magnet_dumbbell_z    62.4 51.8 64.3 48.2 52.1
## roll_dumbbell        36.9 46.1 62.0 48.9 43.3
## magnet_belt_z        41.2 48.8 45.7 58.4 54.4
## pitch_forearm        40.7 44.1 46.5 45.3 45.9
## gyros_belt_z         35.6 43.8 37.7 44.6 46.3
## roll_arm             28.8 44.1 37.7 46.3 33.3
## roll_forearm         34.9 33.0 44.0 31.7 31.6
## yaw_dumbbell         28.4 37.4 42.1 36.8 40.6
## gyros_dumbbell_y     28.6 32.5 40.3 33.2 27.3
## total_accel_dumbbell 31.8 36.0 34.2 33.4 39.9
## magnet_forearm_z     32.9 38.5 31.3 38.0 35.5
## yaw_arm              33.3 38.1 32.4 37.0 32.0
## gyros_arm_x          21.0 36.8 29.3 34.8 29.3
## magnet_belt_x        23.1 36.3 36.8 29.3 36.3
## accel_forearm_x      21.8 31.8 32.4 36.2 29.6
## pitch_arm            24.4 35.5 28.2 30.0 24.6
## accel_forearm_z      22.2 29.6 34.9 29.0 31.0
## magnet_arm_z         28.6 33.8 30.0 31.1 28.6
## accel_arm_y          23.6 32.7 29.2 29.5 27.1</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot(varImp(mod.alt.rf1c, useModel=TRUE, scale=FALSE), top=ncol(mod.alt.rf1c$trainingData)-1)</span>
<span class="kw">dotPlot</span>(<span class="kw">varImp</span>(mod.alt.rf1c, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>), <span class="dt">top=</span><span class="kw">ncol</span>(mod.alt.rf1c$trainingData)-<span class="dv">1</span>)</code></pre>
<p><img src="figures/rf1c_post-plots.png" title="plot of chunk rf1c_post-plots" alt="plot of chunk rf1c_post-plots" width="700" style="display: block; margin: auto auto auto 0;" /></p>
</div>
</div>
<div id="random-forest-case-2-bootstrap-25-reps" class="section level3">
<h3><em>Random Forest</em> case 2 : bootstrap, 25 reps</h3>
<p>With <code>mtry = 2, 6, 10, 18, 26, 34</code></p>
<pre class="sourceCode r"><code class="sourceCode r">mtry.values &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">6</span>, <span class="dv">10</span>, <span class="dv">18</span>, <span class="dv">26</span>, <span class="dv">34</span>)

seed.rf1b &lt;-<span class="st"> </span><span class="dv">16789</span>; <span class="kw">set.seed</span>(seed.rf1b)
mod.rf1b &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> training.cut75[, -<span class="dv">1</span>], 
                      <span class="dt">y =</span> training.cut75$classe, 
                      <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
                      <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">mtry =</span> mtry.values))</code></pre>
<div id="fit-summary-1" class="section level4">
<h4>Fit Summary</h4>
<pre class="sourceCode r"><code class="sourceCode r">mod.rf1b
## Random Forest 
## 
## 14718 samples
##    34 predictors
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## 
## Summary of sample sizes: 14718, 14718, 14718, 14718, 14718, 14718, ... 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD
##   2     1         1      0.002        0.003   
##   6     1         1      0.002        0.002   
##   10    1         1      0.001        0.002   
##   20    1         1      0.002        0.002   
##   30    1         1      0.002        0.003   
##   30    1         1      0.003        0.004   
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 6.
mod.rf1b$finalModel
## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 6
## 
##         OOB estimate of  error rate: 0.64%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4182    3    0    0    0   0.0007168
## B   13 2826    8    0    1   0.0077247
## C    0   19 2530   17    1   0.0144137
## D    0    0   21 2387    4   0.0103648
## E    0    0    2    5 2699   0.0025868
mod.rf1b$results
##   mtry Accuracy  Kappa AccuracySD  KappaSD
## 1    2   0.9880 0.9848   0.002011 0.002541
## 2    6   0.9892 0.9864   0.001674 0.002114
## 3   10   0.9887 0.9857   0.001480 0.001868
## 4   18   0.9866 0.9831   0.001856 0.002344
## 5   26   0.9836 0.9792   0.002145 0.002709
## 6   34   0.9768 0.9707   0.002933 0.003698</code></pre>
</div>
<div id="predictions-on-testing-subset-1" class="section level4">
<h4>Predictions on <em>testing</em> subset</h4>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1b.test75 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rf1b, testing.cut75, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># confusion matrix</span>
<span class="kw">confusionMatrix</span>(testing.cut75$classe, pred.rf1b.test75)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1393    1    0    0    1
##          B    7  936    4    0    2
##          C    0    5  845    4    1
##          D    0    0    5  799    0
##          E    0    0    0    3  898
## 
## Overall Statistics
##                                         
##                Accuracy : 0.993         
##                  95% CI : (0.991, 0.995)
##     No Information Rate : 0.285         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.991         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             0.995    0.994    0.989    0.991    0.996
## Specificity             0.999    0.997    0.998    0.999    0.999
## Pos Pred Value          0.999    0.986    0.988    0.994    0.997
## Neg Pred Value          0.998    0.998    0.998    0.998    0.999
## Prevalence              0.285    0.192    0.174    0.164    0.184
## Detection Rate          0.284    0.191    0.172    0.163    0.183
## Detection Prevalence    0.284    0.194    0.174    0.164    0.184
## Balanced Accuracy       0.997    0.995    0.993    0.995    0.997</code></pre>
</div>
<div id="predictions-on-test-subset-the-20-benchmark-values-for-the-project-1" class="section level4">
<h4>Predictions on <em>TEST</em> subset (the 20 benchmark values for the Project)</h4>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1b.TEST &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.rf1b, TEST.select, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># comparison with &quot;truth&quot;</span>
pred.rf1b.TEST ==<span class="st"> </span>answers
##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [20] TRUE</code></pre>
</div>
<div id="variable-importance-1" class="section level4">
<h4>Variable Importance</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">varImp</span>(mod.rf1b, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>)
## rf variable importance
## 
##   only 20 most important variables shown (out of 34)
## 
##                      Overall
## yaw_belt                1155
## magnet_dumbbell_z        806
## pitch_forearm            763
## magnet_belt_z            698
## roll_forearm             626
## roll_dumbbell            574
## gyros_belt_z             499
## roll_arm                 415
## total_accel_dumbbell     391
## gyros_dumbbell_y         378
## yaw_dumbbell             377
## magnet_forearm_z         342
## accel_forearm_x          333
## magnet_arm_x             327
## accel_forearm_z          320
## pitch_dumbbell           307
## magnet_belt_x            306
## yaw_arm                  285
## magnet_forearm_y         272
## magnet_forearm_x         235</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot(varImp(mod.rf1b, useModel=TRUE, scale=FALSE), top=ncol(mod.rf1b$trainingData)-1)</span>
<span class="kw">dotPlot</span>(<span class="kw">varImp</span>(mod.rf1b, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>), <span class="dt">top=</span><span class="kw">ncol</span>(mod.rf1b$trainingData)-<span class="dv">1</span>)</code></pre>
<p><img src="figures/rf1b_post-plots.png" title="plot of chunk rf1b_post-plots" alt="plot of chunk rf1b_post-plots" width="700" style="display: block; margin: auto auto auto 0;" /></p>
</div>
</div>
<div id="random-forest-case-3-lgocv-25-repeats-7525-splits" class="section level3">
<h3><em>Random Forest</em> case 3 : LGOCV, 25 repeats, 75%/25% splits</h3>
<p>With <code>mtry = 2, 4, 6, 8, 10</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">mtryValues &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">4</span>, <span class="dv">6</span>, <span class="dv">8</span>, <span class="dv">10</span>)

ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;LGOCV&quot;</span>,
                     <span class="dt">classProbs =</span> <span class="ot">TRUE</span>)

seed.rf1e &lt;-<span class="st"> </span><span class="dv">17891</span>; <span class="kw">set.seed</span>(seed.rf1e)
mod.alt.rf1e &lt;-<span class="st"> </span><span class="kw">train</span>(<span class="dt">x =</span> alt.training.cut75[, -<span class="dv">1</span>], 
                  <span class="dt">y =</span> alt.training.cut75$classe, 
                  <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>, 
                  <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">mtry=</span>mtryValues),
                  <span class="dt">trControl =</span> ctrl,
                  <span class="dt">importance =</span> <span class="ot">TRUE</span>, 
                  <span class="dt">proximity =</span> <span class="ot">TRUE</span>)</code></pre>
<div id="fit-summary-2" class="section level4">
<h4>Fit Summary</h4>
<pre class="sourceCode r"><code class="sourceCode r">mod.alt.rf1e
## Random Forest 
## 
## 14414 samples
##    32 predictors
##     5 classes: &#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;, &#39;E&#39; 
## 
## No pre-processing
## Resampling: Repeated Train/Test Splits Estimated (25 reps, 0.75%) 
## 
## Summary of sample sizes: 10812, 10812, 10812, 10812, 10812, 10812, ... 
## 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy  Kappa  Accuracy SD  Kappa SD
##   2     1         1      0.002        0.002   
##   4     1         1      0.001        0.002   
##   6     1         1      0.001        0.002   
##   8     1         1      0.002        0.002   
##   10    1         1      0.002        0.002   
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was mtry = 4.
mod.alt.rf1e$finalModel
## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 4
## 
##         OOB estimate of  error rate: 0.65%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 4101    1    0    1    1    0.000731
## B   18 2764    7    0    0    0.008964
## C    0   19 2483   12    0    0.012331
## D    0    0   28 2330    3    0.013130
## E    0    0    1    3 2642    0.001512
mod.alt.rf1e$results
##   mtry Accuracy  Kappa AccuracySD  KappaSD
## 1    2   0.9897 0.9869   0.001745 0.002209
## 2    4   0.9910 0.9887   0.001204 0.001523
## 3    6   0.9910 0.9886   0.001362 0.001724
## 4    8   0.9907 0.9882   0.001660 0.002101
## 5   10   0.9903 0.9877   0.001702 0.002154</code></pre>
</div>
<div id="predictions-on-testing-subset-2" class="section level4">
<h4>Predictions on <em>testing</em> subset</h4>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1e.test75 &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1e, alt.testing.cut75, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># confusion matrix</span>
<span class="kw">confusionMatrix</span>(alt.testing.cut75$classe, pred.rf1e.test75)
## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1365    2    0    0    0
##          B    0  920    6    0    3
##          C    0    8  823    7    0
##          D    0    0   12  771    3
##          E    0    0    0    1  881
## 
## Overall Statistics
##                                         
##                Accuracy : 0.991         
##                  95% CI : (0.988, 0.994)
##     No Information Rate : 0.284         
##     P-Value [Acc &gt; NIR] : &lt;2e-16        
##                                         
##                   Kappa : 0.989         
##  Mcnemar&#39;s Test P-Value : NA            
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity             1.000    0.989    0.979    0.990    0.993
## Specificity             0.999    0.998    0.996    0.996    1.000
## Pos Pred Value          0.999    0.990    0.982    0.981    0.999
## Neg Pred Value          1.000    0.997    0.995    0.998    0.998
## Prevalence              0.284    0.194    0.175    0.162    0.185
## Detection Rate          0.284    0.192    0.171    0.161    0.183
## Detection Prevalence    0.285    0.193    0.175    0.164    0.184
## Balanced Accuracy       1.000    0.993    0.987    0.993    0.996</code></pre>
</div>
<div id="predictions-on-test-subset-the-20-benchmark-values-for-the-project-2" class="section level4">
<h4>Predictions on <em>TEST</em> subset (the 20 benchmark values for the Project)</h4>
<pre class="sourceCode r"><code class="sourceCode r">pred.rf1e.TEST &lt;-<span class="st"> </span><span class="kw">predict</span>(mod.alt.rf1e, alt.TEST.select, <span class="dt">type=</span><span class="st">&quot;raw&quot;</span>)

<span class="co"># comparison with &quot;truth&quot;</span>
pred.rf1e.TEST ==<span class="st"> </span>answers
##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
## [20] TRUE</code></pre>
</div>
<div id="variable-importance-2" class="section level4">
<h4>Variable Importance</h4>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot(varImp(mod.alt.rf1e, useModel=TRUE, scale=FALSE), top=ncol(mod.alt.rf1e$trainingData)-1)</span>
<span class="kw">dotPlot</span>(<span class="kw">varImp</span>(mod.alt.rf1e, <span class="dt">useModel=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">FALSE</span>), <span class="dt">top=</span><span class="kw">ncol</span>(mod.alt.rf1e$trainingData)-<span class="dv">1</span>)</code></pre>
<p><img src="figures/rf1e_post-plots.png" title="plot of chunk rf1e_post-plots" alt="plot of chunk rf1e_post-plots" width="700" style="display: block; margin: auto auto auto 0;" /></p>
<hr />
</div>
</div>
</div>
<div id="appendices" class="section level2">
<h2>Appendices</h2>
<div id="timed-vs.-summary-data-entries" class="section level3">
<h3><em>Timed</em> vs. <em>summary</em> data entries</h3>
<pre class="sourceCode r"><code class="sourceCode r">alt.statsNA &lt;-<span class="st"> </span><span class="kw">as.data.frame</span>(<span class="kw">t</span>(<span class="kw">sapply</span>(alt.full.good, function(x){ <span class="kw">c</span>(<span class="dt">good =</span> <span class="kw">sum</span>(!<span class="kw">is.na</span>(x)), <span class="dt">bad =</span> <span class="kw">sum</span>(<span class="kw">is.na</span>(x)))})))
<span class="kw">print</span>(alt.statsNA, <span class="dt">quote=</span><span class="ot">FALSE</span>, <span class="dt">print.gap=</span><span class="dv">5</span>)
##                               good       bad
## classe                       19216         0
## total_accel_belt             19216         0
## var_accel_belt                   0     19216
## roll_belt                    19216         0
## avg_roll_belt                    0     19216
## stddev_roll_belt                 0     19216
## var_roll_belt                    0     19216
## kurtosis_roll_belt               0     19216
## skewness_roll_belt               0     19216
## min_roll_belt                    0     19216
## max_roll_belt                    0     19216
## amplitude_roll_belt              0     19216
## pitch_belt                   19216         0
## avg_pitch_belt                   0     19216
## stddev_pitch_belt                0     19216
## var_pitch_belt                   0     19216
## kurtosis_pitch_belt              0     19216
## skewness_pitch_belt              0     19216
## min_pitch_belt                   0     19216
## max_pitch_belt                   0     19216
## amplitude_pitch_belt             0     19216
## yaw_belt                     19216         0
## avg_yaw_belt                     0     19216
## stddev_yaw_belt                  0     19216
## var_yaw_belt                     0     19216
## kurtosis_yaw_belt                0     19216
## skewness_yaw_belt                0     19216
## min_yaw_belt                     0     19216
## max_yaw_belt                     0     19216
## amplitude_yaw_belt               0     19216
## gyros_belt_x                 19216         0
## gyros_belt_y                 19216         0
## gyros_belt_z                 19216         0
## accel_belt_x                 19216         0
## accel_belt_y                 19216         0
## accel_belt_z                 19216         0
## magnet_belt_x                19216         0
## magnet_belt_y                19216         0
## magnet_belt_z                19216         0
## total_accel_arm              19216         0
## var_accel_arm                    0     19216
## roll_arm                     19216         0
## avg_roll_arm                     0     19216
## stddev_roll_arm                  0     19216
## var_roll_arm                     0     19216
## kurtosis_roll_arm                0     19216
## skewness_roll_arm                0     19216
## min_roll_arm                     0     19216
## max_roll_arm                     0     19216
## amplitude_roll_arm               0     19216
## pitch_arm                    19216         0
## avg_pitch_arm                    0     19216
## stddev_pitch_arm                 0     19216
## var_pitch_arm                    0     19216
## kurtosis_pitch_arm               0     19216
## skewness_pitch_arm               0     19216
## min_pitch_arm                    0     19216
## max_pitch_arm                    0     19216
## amplitude_pitch_arm              0     19216
## yaw_arm                      19216         0
## avg_yaw_arm                      0     19216
## stddev_yaw_arm                   0     19216
## var_yaw_arm                      0     19216
## kurtosis_yaw_arm                 0     19216
## skewness_yaw_arm                 0     19216
## min_yaw_arm                      0     19216
## max_yaw_arm                      0     19216
## amplitude_yaw_arm                0     19216
## gyros_arm_x                  19216         0
## gyros_arm_y                  19216         0
## gyros_arm_z                  19216         0
## accel_arm_x                  19216         0
## accel_arm_y                  19216         0
## accel_arm_z                  19216         0
## magnet_arm_x                 19216         0
## magnet_arm_y                 19216         0
## magnet_arm_z                 19216         0
## total_accel_forearm          19216         0
## var_accel_forearm                0     19216
## roll_forearm                 19216         0
## avg_roll_forearm                 0     19216
## stddev_roll_forearm              0     19216
## var_roll_forearm                 0     19216
## kurtosis_roll_forearm            0     19216
## skewness_roll_forearm            0     19216
## min_roll_forearm                 0     19216
## max_roll_forearm                 0     19216
## amplitude_roll_forearm           0     19216
## pitch_forearm                19216         0
## avg_pitch_forearm                0     19216
## stddev_pitch_forearm             0     19216
## var_pitch_forearm                0     19216
## kurtosis_pitch_forearm           0     19216
## skewness_pitch_forearm           0     19216
## min_pitch_forearm                0     19216
## max_pitch_forearm                0     19216
## amplitude_pitch_forearm          0     19216
## yaw_forearm                  19216         0
## avg_yaw_forearm                  0     19216
## stddev_yaw_forearm               0     19216
## var_yaw_forearm                  0     19216
## kurtosis_yaw_forearm             0     19216
## skewness_yaw_forearm             0     19216
## min_yaw_forearm                  0     19216
## max_yaw_forearm                  0     19216
## amplitude_yaw_forearm            0     19216
## gyros_forearm_x              19216         0
## gyros_forearm_y              19216         0
## gyros_forearm_z              19216         0
## accel_forearm_x              19216         0
## accel_forearm_y              19216         0
## accel_forearm_z              19216         0
## magnet_forearm_x             19216         0
## magnet_forearm_y             19216         0
## magnet_forearm_z             19216         0
## total_accel_dumbbell         19216         0
## var_accel_dumbbell               0     19216
## roll_dumbbell                19216         0
## avg_roll_dumbbell                0     19216
## stddev_roll_dumbbell             0     19216
## var_roll_dumbbell                0     19216
## kurtosis_roll_dumbbell           0     19216
## skewness_roll_dumbbell           0     19216
## min_roll_dumbbell                0     19216
## max_roll_dumbbell                0     19216
## amplitude_roll_dumbbell          0     19216
## pitch_dumbbell               19216         0
## avg_pitch_dumbbell               0     19216
## stddev_pitch_dumbbell            0     19216
## var_pitch_dumbbell               0     19216
## kurtosis_pitch_dumbbell          0     19216
## skewness_pitch_dumbbell          0     19216
## min_pitch_dumbbell               0     19216
## max_pitch_dumbbell               0     19216
## amplitude_pitch_dumbbell         0     19216
## yaw_dumbbell                 19216         0
## avg_yaw_dumbbell                 0     19216
## stddev_yaw_dumbbell              0     19216
## var_yaw_dumbbell                 0     19216
## kurtosis_yaw_dumbbell            0     19216
## skewness_yaw_dumbbell            0     19216
## min_yaw_dumbbell                 0     19216
## max_yaw_dumbbell                 0     19216
## amplitude_yaw_dumbbell           0     19216
## gyros_dumbbell_x             19216         0
## gyros_dumbbell_y             19216         0
## gyros_dumbbell_z             19216         0
## accel_dumbbell_x             19216         0
## accel_dumbbell_y             19216         0
## accel_dumbbell_z             19216         0
## magnet_dumbbell_x            19216         0
## magnet_dumbbell_y            19216         0
## magnet_dumbbell_z            19216         0</code></pre>
</div>
<div id="checking-for-zerolow-variance-predictors." class="section level3">
<h3>Checking for zero/low variance predictors.</h3>
<pre class="sourceCode r"><code class="sourceCode r">nzv &lt;-<span class="st"> </span><span class="kw">nearZeroVar</span>(alt.full.select, <span class="dt">saveMetrics=</span><span class="ot">TRUE</span>)
nzv
##                      freqRatio percentUnique zeroVar   nzv
## classe                   1.471       0.02602   FALSE FALSE
## total_accel_belt         1.069       0.15092   FALSE FALSE
## roll_belt                1.086       6.83805   FALSE FALSE
## pitch_belt               1.037       9.53893   FALSE FALSE
## yaw_belt                 1.047      10.10616   FALSE FALSE
## gyros_belt_x             1.051       0.72336   FALSE FALSE
## gyros_belt_y             1.149       0.35908   FALSE FALSE
## gyros_belt_z             1.071       0.87948   FALSE FALSE
## accel_belt_x             1.059       0.85346   FALSE FALSE
## accel_belt_y             1.115       0.74417   FALSE FALSE
## accel_belt_z             1.081       1.55600   FALSE FALSE
## magnet_belt_x            1.089       1.70171   FALSE FALSE
## magnet_belt_y            1.097       1.55079   FALSE FALSE
## magnet_belt_z            1.019       2.37302   FALSE FALSE
## total_accel_arm          1.020       0.34346   FALSE FALSE
## roll_arm                51.154      13.75937   FALSE FALSE
## pitch_arm               85.282      15.96066   FALSE FALSE
## yaw_arm                 32.282      14.89904   FALSE FALSE
## gyros_arm_x              1.024       3.34617   FALSE FALSE
## gyros_arm_y              1.451       1.95150   FALSE FALSE
## gyros_arm_z              1.119       1.29059   FALSE FALSE
## accel_arm_x              1.018       4.04351   FALSE FALSE
## accel_arm_y              1.169       2.78414   FALSE FALSE
## accel_arm_z              1.139       4.12157   FALSE FALSE
## magnet_arm_x             1.012       6.96295   FALSE FALSE
## magnet_arm_y             1.045       4.53268   FALSE FALSE
## magnet_arm_z             1.028       6.57785   FALSE FALSE
## total_accel_forearm      1.133       0.36428   FALSE FALSE
## roll_forearm            11.726      11.23543   FALSE FALSE
## pitch_forearm           64.576      15.09679   FALSE FALSE
## yaw_forearm             15.236      10.29871   FALSE FALSE
## gyros_forearm_x          1.050       1.54559   FALSE FALSE
## gyros_forearm_y          1.043       3.84055   FALSE FALSE
## gyros_forearm_z          1.112       1.58201   FALSE FALSE
## accel_forearm_x          1.143       4.13197   FALSE FALSE
## accel_forearm_y          1.050       5.20920   FALSE FALSE
## accel_forearm_z          1.019       3.01311   FALSE FALSE
## magnet_forearm_x         1.013       7.92569   FALSE FALSE
## magnet_forearm_y         1.256       9.72627   FALSE FALSE
## magnet_forearm_z         1.018       8.75833   FALSE FALSE
## total_accel_dumbbell     1.081       0.22377   FALSE FALSE
## roll_dumbbell            1.038      83.75312   FALSE FALSE
## pitch_dumbbell           2.248      81.22398   FALSE FALSE
## yaw_dumbbell             1.132      83.02456   FALSE FALSE
## gyros_dumbbell_x         1.010       1.25416   FALSE FALSE
## gyros_dumbbell_y         1.271       1.44151   FALSE FALSE
## gyros_dumbbell_z         1.053       1.06682   FALSE FALSE
## accel_dumbbell_x         1.006       2.21170   FALSE FALSE
## accel_dumbbell_y         1.062       2.41986   FALSE FALSE
## accel_dumbbell_z         1.150       2.12323   FALSE FALSE
## magnet_dumbbell_x        1.094       5.84929   FALSE FALSE
## magnet_dumbbell_y        1.189       4.38177   FALSE FALSE
## magnet_dumbbell_z        1.027       3.51270   FALSE FALSE</code></pre>
</div>
<div id="some-handy-functions" class="section level3">
<h3>Some handy functions</h3>
<pre class="sourceCode r"><code class="sourceCode r">tidy_df &lt;-<span class="st"> </span>function( data ) {
    for(i in <span class="dv">8</span>:<span class="dv">159</span>) { 
        data[,i] &lt;-<span class="st"> </span><span class="kw">as.numeric</span>(data[,i])
    }
    <span class="kw">colnames</span>(data) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_picth&quot;</span>, <span class="st">&quot;_pitch&quot;</span>, <span class="kw">colnames</span>(data), <span class="dt">perl=</span><span class="ot">TRUE</span>)
    <span class="kw">colnames</span>(data) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;var_total_accel_&quot;</span>, <span class="st">&quot;var_accel_&quot;</span>, <span class="kw">colnames</span>(data), <span class="dt">perl=</span><span class="ot">TRUE</span>)
    <span class="kw">colnames</span>(data) &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;roll_belt.1&quot;</span>, <span class="st">&quot;pitch_belt&quot;</span>, <span class="kw">colnames</span>(data), <span class="dt">perl=</span><span class="ot">TRUE</span>)
    <span class="kw">return</span>(data)
}

add_new_variables &lt;-<span class="st"> </span>function( data ) { 
    data$classe &lt;-<span class="st"> </span><span class="kw">as.factor</span>(data$classe)
    data$timestamp &lt;-<span class="st"> </span>data$raw_timestamp_part_1 +<span class="st"> </span>data$raw_timestamp_part_2
    data$date &lt;-<span class="st"> </span><span class="kw">strptime</span>(<span class="kw">as.character</span>(data$cvtd_timestamp), <span class="st">&quot;%d/%m/%Y %H:%M&quot;</span>)
    <span class="kw">return</span>(data)
}

select_proper_vars &lt;-<span class="st"> </span>function( data ) {
    vec0 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;total_accel&quot;</span>, <span class="st">&quot;var_accel&quot;</span>)
    
    nn1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;avg&quot;</span>, <span class="st">&quot;stddev&quot;</span>, <span class="st">&quot;var&quot;</span>, <span class="st">&quot;kurtosis&quot;</span>, <span class="st">&quot;skewness&quot;</span>, <span class="st">&quot;min&quot;</span>, <span class="st">&quot;max&quot;</span>, <span class="st">&quot;amplitude&quot;</span>)
    vec1 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;roll&quot;</span>, <span class="kw">paste</span>(nn1, <span class="st">&quot;roll&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>), 
              <span class="st">&quot;pitch&quot;</span>, <span class="kw">paste</span>(nn1, <span class="st">&quot;pitch&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>), 
              <span class="st">&quot;yaw&quot;</span>, <span class="kw">paste</span>(nn1, <span class="st">&quot;yaw&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>))
    
    nn2 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;gyros&quot;</span>, <span class="st">&quot;accel&quot;</span>, <span class="st">&quot;magnet&quot;</span>)
    vec2 &lt;-<span class="st"> </span><span class="kw">paste</span>( <span class="kw">rep</span>(nn2, <span class="dt">each=</span><span class="dv">3</span>), <span class="st">&quot;VVV&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;x&quot;</span>,<span class="st">&quot;y&quot;</span>,<span class="st">&quot;z&quot;</span>), <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>)
    
    vec.VVV &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">paste</span>(<span class="kw">c</span>(<span class="st">&quot;total_accel&quot;</span>, <span class="st">&quot;var_accel&quot;</span>, vec1), <span class="st">&quot;VVV&quot;</span>, <span class="dt">sep=</span><span class="st">&quot;_&quot;</span>), vec2)
    vec.belt &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_belt&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    vec.arm &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_arm&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    vec.forearm &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_forearm&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    vec.dumbbell &lt;-<span class="st"> </span><span class="kw">gsub</span>(<span class="st">&quot;_VVV&quot;</span>, <span class="st">&quot;_dumbbell&quot;</span>, vec.VVV, <span class="dt">perl=</span><span class="ot">TRUE</span>)
    i.classe &lt;-<span class="st"> </span><span class="kw">which</span>( <span class="kw">colnames</span>(data) ==<span class="st"> &quot;classe&quot;</span>)
    
    if( <span class="kw">length</span>(i.classe) &gt;<span class="st"> </span><span class="dv">0</span> ) {
        select &lt;-<span class="st"> </span>data[, <span class="kw">c</span>(<span class="st">&quot;classe&quot;</span>, vec.belt, vec.arm, vec.forearm, vec.dumbbell)]
    } else {
        select &lt;-<span class="st"> </span>data[, <span class="kw">c</span>(<span class="st">&quot;problem_id&quot;</span>, vec.belt, vec.arm, vec.forearm, vec.dumbbell)]
    }
    <span class="kw">return</span>(select)
}

<span class="co"># define color palettes</span>
color1 &lt;-<span class="st"> </span><span class="kw">colorRampPalette</span>(<span class="kw">c</span>(<span class="st">&quot;#7F0000&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;#FF7F00&quot;</span>, <span class="st">&quot;yellow&quot;</span>, <span class="st">&quot;white&quot;</span>, <span class="st">&quot;cyan&quot;</span>, <span class="st">&quot;#007FFF&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;#00007F&quot;</span>))
color2 &lt;-<span class="st"> </span><span class="kw">colorRampPalette</span>(<span class="kw">c</span>(<span class="st">&quot;#67001F&quot;</span>, <span class="st">&quot;#B2182B&quot;</span>, <span class="st">&quot;#D6604D&quot;</span>, <span class="st">&quot;#F4A582&quot;</span>, <span class="st">&quot;#FDDBC7&quot;</span>,
                           <span class="st">&quot;#FFFFFF&quot;</span>, <span class="st">&quot;#D1E5F0&quot;</span>, <span class="st">&quot;#92C5DE&quot;</span>, <span class="st">&quot;#4393C3&quot;</span>, <span class="st">&quot;#2166AC&quot;</span>, <span class="st">&quot;#053061&quot;</span>))   
color3 &lt;-<span class="st"> </span><span class="kw">colorRampPalette</span>(<span class="kw">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;white&quot;</span>, <span class="st">&quot;blue&quot;</span>))   

<span class="co"># correct answers</span>
answers &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;D&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;C&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;E&quot;</span>, <span class="st">&quot;A&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>, <span class="st">&quot;B&quot;</span>)</code></pre>
<hr />
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

<!-- dynamically load mathjax for compatibility with --self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
